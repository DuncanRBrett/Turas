Turas MaxDiff ModuleTechnical Specification for DevelopmentVersion 1.0December 2025
1. Executive SummaryThis specification defines the Turas MaxDiff module, an R-based system for creating optimal MaxDiff experimental designs and analysing Best-Worst scaling data. The module supports two operational modes: DESIGN mode for generating experimental designs, and ANALYSIS mode for processing survey responses and computing preference scores.1.1 Key Features¥ Excel-based configuration for non-technical users¥ Balanced Incomplete Block Design (BIBD) generation with optimisation¥ Hierarchical Bayes estimation via Stan for individual-level utilities¥ Aggregate and segment-level analysis with multiple scoring methods¥ Comprehensive validation, logging, and reproducibility features¥ Publication-ready visualisations using ggplot21.2 Required R PackagesThe module uses best-in-class R packages for each component:PackageVersionPurposereadxl³1.4.0Excel file readingopenxlsx³4.2.5Excel file writing with formattingtidyverse³2.0.0Data manipulation (dplyr, tidyr, purrr, stringr)cmdstanr³0.6.0Hierarchical Bayes estimation via StanAlgDesign³1.2.1Optimal experimental design generationggplot2³3.4.0Publication-quality visualisationslogger³0.2.0Structured logging with levelscli³3.6.0Console progress bars and formattingcheckmate³2.1.0Fast argument validation
2. Excel Configuration WorkbookAll module settings are defined in a single Excel workbook with six sheets. This design allows researchers to configure studies without writing code.2.1 PROJECT_SETTINGS SheetGlobal project parameters in a two-column key-value format:Setting_NameExample ValueDescriptionProject_NameBankX_Benefits_2025Unique project identifier (no spaces)Module_Versionv1.0For audit trailModeANALYSISDESIGN or ANALYSISRaw_Data_Filedata/responses.xlsxPath to survey data (relative to project root)Data_File_Sheetmaxdiff_dataSheet name in data fileDesign_Fileconfig/design.xlsxPath to design fileOutput_Folderoutput/MaxDiffOutput directoryWeight_VariableweightColumn name for weights (blank = unweighted)Respondent_ID_VariableRespIDUnique respondent identifier columnFilter_ExpressionWave==2025 & Complete==1R expression for filtering (blank = no filter)Seed12345Random seed for reproducibility2.2 ITEMS SheetDefines all items/attributes to be evaluated:ColumnExampleRequiredTypeDefaultNotesItem_IDB01YesString--Item_LabelLow monthly feesYesString--Item_GroupFunctionalNoStringblankFor grouping in outputInclude1Yes0/11Include in designAnchor_Item0No0/10HB anchor referenceDisplay_Order1NoIntegerItem_ID orderOutput sortingNotesNew for 2025NoStringblankDocumentation2.3 DESIGN_SETTINGS SheetParameters for experimental design generation (DESIGN mode):Parameter_NameExampleDescriptionItems_Per_Task4Number of items shown in each task (typically 4-5)Tasks_Per_Respondent12Number of tasks each respondent completesNum_Versions3Number of design versions to createDesign_TypeBALANCEDBALANCED, RANDOM, or OPTIMALAllow_Item_Repeat_Per_RespondentYESAllow items to appear multiple times per respondentMax_Item_Repeats5Maximum times an item can appear per respondentForce_Min_Pair_BalanceYESEnsure all item pairs appear roughly equallyRandomise_Task_OrderYESRandomise task presentation orderRandomise_Item_Order_Within_TaskYESRandomise item order within each taskDesign_Efficiency_Threshold0.90Minimum D-efficiency for OPTIMAL designsMax_Design_Iterations10000Maximum iterations for design optimisation2.4 SURVEY_MAPPING SheetMaps survey platform column names to module expectations:Field_TypeField_NameTask_NumberNotesVERSIONMD_Version-Design version assigned to respondentBEST_CHOICEMD_Best_011Column containing chosen best Item_ID for task 1WORST_CHOICEMD_Worst_011Column containing chosen worst Item_ID for task 1BEST_CHOICEMD_Best_022... repeat for all tasks ...WORST_CHOICEMD_Worst_022SHOWN_ITEMSMD_Shown_011Optional: comma-separated items shown (overrides design)2.5 SEGMENT_SETTINGS SheetDefines segments for subgroup analysis:Segment_IDSegment_LabelVariable_NameSegment_DefInclude_in_OutputGENDERGenderGender1AGE3Age GroupsAgecut(Age,c(0,29,44,120),labels=c("18-29","30-44","45+"))1REGIONRegionRegion1Note: If Segment_Def is blank, the raw categories in Variable_Name are used directly.2.6 OUTPUT_SETTINGS SheetControls which outputs are generated and their format:Option_NameExampleDescriptionGenerate_Design_FileYESOutput design matrix (DESIGN mode)Generate_Count_ScoresYESCompute Best/Worst count scoresGenerate_Aggregate_LogitYESFit aggregate conditional logit modelGenerate_HB_ModelYESFit Hierarchical Bayes model via StanHB_Iterations5000MCMC iterations for HB (after warmup)HB_Warmup2000Warmup iterations for HBHB_Chains4Number of MCMC chainsGenerate_Segment_TablesYESCompute segment-level scoresGenerate_ChartsYESGenerate ggplot2 visualisationsScore_Rescale_Method0_100RAW, 0_100, or PROBABILITYMin_Respondents_Per_Segment50Minimum n to report segmentOutput_Item_Sort_OrderUTILITY_DESCUTILITY_DESC, UTILITY_ASC, ITEM_ID, or DISPLAY_ORDERExport_Individual_UtilsYESExport respondent-level utilities from HB
3. Design File FormatThe design file (generated in DESIGN mode or provided externally) specifies which items appear in each task for each version.3.1 DESIGN Sheet StructureVersionTask_NumberItem1_IDItem2_IDItem3_IDItem4_ID11B01B04B07B0912B02B03B06B1021B03B05B07B103.2 DESIGN_SUMMARY SheetGenerated automatically with design diagnostics:¥ Item frequency table (times each item appears)¥ Pair frequency matrix (how often each pair appears together)¥ Position balance (item distribution across positions 1-k)¥ D-efficiency score for the design¥ Version-level statistics
4. Module Architecture4.1 File Structureturas/??? R/?   ??? maxdiff_main.R          # Entry point and orchestration?   ??? maxdiff_config.R        # Configuration loading and validation?   ??? maxdiff_design.R        # Design generation functions?   ??? maxdiff_analysis.R      # Analysis orchestration?   ??? maxdiff_data.R          # Data loading and reshaping?   ??? maxdiff_counts.R        # Count-based scoring?   ??? maxdiff_logit.R         # Aggregate logit estimation?   ??? maxdiff_hb.R            # Hierarchical Bayes estimation?   ??? maxdiff_segments.R      # Segment analysis?   ??? maxdiff_output.R        # Excel output generation?   ??? maxdiff_charts.R        # ggplot2 visualisations?   ??? maxdiff_utils.R         # Utility functions??? stan/?   ??? maxdiff_hb.stan         # Stan model for HB estimation??? tests/    ??? testthat/               # Unit tests4.2 Core Functions4.2.1 Entry Pointrun_maxdiff_module(config_path, project_root = ".")Main entry point that loads configuration, determines mode, and dispatches to appropriate workflow.4.2.2 Configurationload_maxdiff_config(config_path, project_root)validate_maxdiff_config(cfg)Loads Excel config into a structured list and validates all required fields, cross-sheet consistency, and file existence.4.2.3 Design Generationrun_maxdiff_design(cfg)generate_maxdiff_design(item_ids, items_per_task, tasks_per_resp, ...)evaluate_design_efficiency(design)summarise_maxdiff_design(design, items)4.2.4 Analysis Pipelinerun_maxdiff_analysis(cfg)build_maxdiff_long(raw_df, survey_mapping, design, cfg)compute_maxdiff_counts(long_df, items)fit_aggregate_logit(long_df, items, weights)fit_hb_model(long_df, items, cfg)compute_segment_scores(long_df, segment_settings, items)
5. Design Mode Specification5.1 Design TypesBALANCED: Uses a near-balanced incomplete block design where each item appears approximately equally often and each pair appears together approximately equally often. Generated via iterative random sampling with balance constraints.OPTIMAL: Uses AlgDesign::optFederov() to generate a D-optimal design that maximises information for parameter estimation. Recommended for studies with many items or constraints.RANDOM: Pure random allocation with no balance constraints. Only for testing purposes.5.2 Design Quality MetricsThe module computes and reports:1. D-efficiency: Ratio of design's D-value to theoretical optimum (0-1 scale, higher is better)2. Item balance coefficient of variation: CV of item frequencies (lower is better)3. Pair balance coefficient of variation: CV of pair frequencies (lower is better)4. Position balance: Distribution of items across positions within tasks5.3 Recommended Design ParametersItemsItems_Per_TaskTasksNotes6-1048-12Standard configuration11-154-512-15May need more versions16-25515-20Consider sparse design26+5-615-25Use OPTIMAL design type
6. Analysis Mode Specification6.1 Data Processing Pipeline1. Load and validate raw survey data2. Apply filter expression if specified3. Join data with design to identify items shown in each task4. Reshape to long format (one row per item-task-respondent combination)5. Create binary indicators for best/worst choices6. Apply weights if specified6.2 Scoring Methods6.2.1 Count-Based ScoresSimple descriptive metrics computed directly from choice frequencies:¥ Best%: Proportion of times item was chosen as best when shown¥ Worst%: Proportion of times item was chosen as worst when shown¥ Net Score: (Best% - Worst%)¥ Best-Worst Score: (#Best - #Worst) / #Shown6.2.2 Aggregate Logit ModelConditional logit model treating best/worst choices as separate choice tasks:P(item i chosen as Best | set S) = exp(?_i) / ?_j?S exp(?_j)P(item i chosen as Worst | set S) = exp(-?_i) / ?_j?S exp(-?_j)Implemented using survival::clogit() for computational efficiency with large datasets.6.2.3 Hierarchical Bayes ModelEstimates individual-level utilities using a hierarchical model:?_n ~ MVN(?, ?)           # Population distribution of utilities? ~ MVN(0, ??_? I)        # Prior on population mean? ~ LKJ(?) ? half-t(?)   # Prior on covariance (correlation + scales)Implemented using cmdstanr for efficient MCMC sampling. The Stan model uses non-centered parameterisation for improved sampling geometry.6.3 Score RescalingMethodFormulaRAWNo transformation; utilities as estimated0_100100 ? (?_i - min(?)) / (max(?) - min(?))PROBABILITYexp(?_i) / ? exp(?_j) Ñ probability share of preference
7. Output Specification7.1 Excel Output WorkbookMain results file: {Project_Name}_MaxDiff_Results.xlsxSheet: SUMMARY¥ Project metadata and settings used¥ Sample sizes (total and per version)¥ Data quality metrics¥ Model fit statisticsSheet: ITEM_SCORESColumnDescriptionItem_IDItem identifierItem_LabelFull item textItem_GroupGrouping categoryTimes_ShownWeighted count of times shownTimes_BestWeighted count chosen as bestTimes_WorstWeighted count chosen as worstBest_PctPercentage chosen as bestWorst_PctPercentage chosen as worstNet_ScoreBest% - Worst%Logit_UtilityAggregate logit utility (if generated)Logit_SEStandard error of logit utilityHB_Utility_MeanMean HB utility (if generated)HB_Utility_SDSD of HB utility across respondentsRescaled_ScoreUtility rescaled per Score_Rescale_MethodRankRank based on Rescaled_ScoreSheet: SEGMENT_SCORESSame columns as ITEM_SCORES plus: Segment_ID, Segment_Label, Segment_Value, Segment_NSheet: INDIVIDUAL_UTILS (Optional)When Export_Individual_Utils = YES and HB model is run:¥ Respondent_ID¥ One column per item with individual utility estimate¥ Segment variables for mergingSheet: MODEL_DIAGNOSTICS¥ Logit model: Log-likelihood, AIC, BIC, McFadden pseudo-R?¥ HB model: Rhat values, effective sample sizes, divergences, chain diagnostics7.2 Chart OutputsAll charts saved as PNG (300 DPI) to output folder:¥ {Project_Name}_utility_bar.png Ñ Horizontal bar chart of rescaled scores¥ {Project_Name}_best_worst.png Ñ Diverging bar chart showing Best% and Worst%¥ {Project_Name}_segment_{SegmentID}.png Ñ Comparison across segment levels¥ {Project_Name}_utility_distribution.png Ñ Violin/boxplot of individual utilities (HB)
8. Error Handling and Validation8.1 Configuration ValidationThe module validates the following on startup:1. All required sheets exist in config workbook2. Required settings have valid values3. Referenced files exist and are readable4. Item_IDs are unique and non-empty5. Survey mapping references valid column names6. Filter expression is valid R syntax7. Design file matches items in config8.2 Data Validation1. Respondent IDs are unique2. Best/Worst choices reference valid Item_IDs3. Chosen items were actually shown in the task4. No duplicate choices (best ­ worst in same task)5. Weights are positive (if specified)6. Version numbers match design file8.3 LoggingThe module uses the logger package with the following levels:¥ INFO: Progress updates, sample sizes, model convergence¥ WARN: Data quality issues that don't prevent analysis (e.g., small segment n)¥ ERROR: Fatal errors with clear remediation guidanceLog output written to both console and {Output_Folder}/{Project_Name}_log.txt
9. Stan Model SpecificationThe Hierarchical Bayes model is implemented in Stan (stan/maxdiff_hb.stan):data {  int<lower=1> N;              // Number of choice observations  int<lower=1> R;              // Number of respondents  int<lower=2> J;              // Number of items  int<lower=2> K;              // Items per task  array[N] int<lower=1,upper=R> resp;     // Respondent index  array[N] int<lower=1,upper=J> choice;   // Chosen item index  array[N, K] int<lower=1,upper=J> shown; // Items shown in task  array[N] int<lower=0,upper=1> is_best;  // 1=best choice, 0=worst}parameters {  vector[J-1] mu_raw;          // Population mean (anchor at 0)  vector<lower=0>[J-1] sigma;  // Population SD  cholesky_factor_corr[J-1] L; // Correlation Cholesky factor  matrix[R, J-1] z;            // Standard normal deviates}transformed parameters {  matrix[R, J] beta;           // Individual utilities  // Non-centered parameterisation with anchor  beta[, 1:(J-1)] = rep_matrix(mu_raw', R) +                    z * diag_pre_multiply(sigma, L)';  beta[, J] = rep_vector(0, R); // Anchor item}model {  // Priors  mu_raw ~ normal(0, 2);  sigma ~ student_t(3, 0, 1);  L ~ lkj_corr_cholesky(2);  to_vector(z) ~ std_normal();    // Likelihood  for (n in 1:N) {    vector[K] utils;    for (k in 1:K) {      utils[k] = is_best[n] ? beta[resp[n], shown[n,k]]                           : -beta[resp[n], shown[n,k]];    }    target += utils[choice[n]] - log_sum_exp(utils);  }}
10. Testing Requirements10.1 Unit TestsRequired test coverage using testthat:1. Configuration loading with valid/invalid inputs2. Design generation produces valid designs3. Data reshaping produces correct long format4. Count scores match hand calculations5. Logit model converges on test data6. HB model recovers known utilities from simulated data7. Excel output files are valid and readable10.2 Integration Tests1. End-to-end DESIGN mode with example config2. End-to-end ANALYSIS mode with simulated data3. Round-trip: generate design ? simulate choices ? recover utilities
11. Example Usage11.1 Running the Module# From R consolesource("R/maxdiff_main.R")# Run in DESIGN moderun_maxdiff_module(  config_path = "config/BankX_Benefits_Config.xlsx",  project_root = "/path/to/project")# Run in ANALYSIS mode (set Mode = ANALYSIS in config)run_maxdiff_module(  config_path = "config/BankX_Benefits_Config.xlsx",  project_root = "/path/to/project")11.2 Typical Workflow4. Create Excel config with ITEMS and DESIGN_SETTINGS5. Set Mode = DESIGN and run module to generate design6. Program survey platform using generated design file7. Collect data and export to Excel8. Update config: Mode = ANALYSIS, add SURVEY_MAPPING9. Run module to generate resultsÑ End of Specification ÑTuras MaxDiff Module - Technical Specification v1.0Page 1 of 2